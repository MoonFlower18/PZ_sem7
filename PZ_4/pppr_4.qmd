---
title: "Практическое задание №4"
author: "Журавлева Юлия БИСО-01-20"
format: 
  md:
    output-file: README.md
---
# Исследование метаданных DNS трафика

## Цель работы

1. Закрепить практические навыки использования языка программирования R для
обработки данных
2. Закрепить знания основных функций обработки данных экосистемы `tidyverse`
языка R
3. Закрепить навыки исследования метаданных DNS трафика

## Исходные данные

1.  ОС Windows 10
2.  RStudio Desktop
3.  Интерпретатор языка R 4.2.2
4.  Пакет `dplyr`
5.  Файл `dns.log`
6.  Файл `header.csv`  

## План

1. Импортировать данные DNS
2. Ответить на поставленные задачи.

## Ход выполнения работы

***Часть 1. Подготовка данных***

**1. Импортировать данные DNS**

Подключим библиотеки

```{r}
library(dplyr)
library(readr)
library(jsonlite)
```


Для начала импортируем файл `header.csv` и занесём его в переменную `headr`

```{r}
headr <- read_delim("header.csv", delim = ",")
```

Импортируем данные DNS из файла `dns.log` и занесём его в переменную `dns_l`

```{r}
dns_l <- read_delim("dns.log", col_names = FALSE, delim = "\t")
```

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

**2-3. Добавить пропущенные данные о структуре данных (назначении столбцов). Преобразовать данные в столбцах в нужный формат.**

```{r}
colnames(dns_l) <- headr[,1] %>% unlist()
dns_l %>% glimpse()
```

**4. Просмотреть общую структуру данных с помощью функции `glimpse()`**

```{r}
dns_l %>% glimpse()
```

***Часть 2. Анализ***

**4. Сколько участников информационного обмена в сети Доброй Организации?**

```{r}
uni_id <- unique(dns_l$`id.orig_h`)
uni_proto <- unique(dns_l$`id.resp_h`)
uni_user <- union(uni_id , uni_proto)
uni_user %>% length()
```

**5. Какое соотношение участников обмена внутри сети и участников обращений к внешним ресурсам?**

Диапазоны ip-адресов:

1.  10.0.0.0 - 10.255.255.255
2.  100.64.0.0 - 100.127.255.255
3.  172.16.0.0 - 172.31.255.255
4.  192.168.0.0 - 192.168.255.255

```{r}
ip_all <- c("10.", "100.([6-9]|1[0-1][0-9]|12[0-7]).", "172.((1[6-9])|(2[0-9])|(3[0-1])).", "192.168.")
internal_ips <- uni_user[grep(paste(ip_all, collapse = "|"), uni_user)]
sum_int <- sum(uni_user %in% internal_ips)
count_ext <- length(uni_user) - sum_int

rate <- sum_int / count_ext
rate
```

**6. Найдите топ-10 участников сети, проявляющих наибольшую сетевую активность**

```{r}
users_top_10 <- dns_l %>% 
  group_by(ip = id.orig_h) %>% 
  summarise(num_activ = n()) %>% 
  arrange(desc(num_activ))

users_top_10 %>% head(10)
```

**7. Найдите топ-10 доменов, к которым обращаются пользователи сети и соответственное количество обращений**

Для начала, создадим датафрейм, который будет включать в себя только нужную информацию без мусора (чтобы `qtype_name` включал в себя "А" и "АААА"). Убедимся, что в начале и в конце есть оба значения.

```{r}
filtered_df <- subset(dns_l, dns_l$`qtype_name ` == "A")
filtered_df_2 <- subset(dns_l, dns_l$`qtype_name ` == "AAAA")
merged_df <- union(filtered_df_2, filtered_df)

merged_df %>% head(10)
merged_df %>% tail(10)
```

Выводим ТОП-10 доменов.

```{r}
domains_top_10 <- merged_df %>% 
  group_by(address = merged_df$`query `) %>% 
  summarise(req_count = n()) %>% 
  arrange(desc(req_count))

domains_top_10 %>% 
  .[-10,] %>% 
  head(10)
```

**8. Опеределите базовые статистические характеристики (функция `summary()`) интервала времени между последовательным обращениями к топ-10 доменам.**

```{r}
domains_top_10_new <- dns_l %>% 
  filter(tolower(dns_l$`query `) %in% domains_top_10$address) %>% 
  arrange(`ts `)

timing <- diff(dns_l$`ts `)

summary(timing)
```

**9. Часто вредоносное программное обеспечение использует DNS канал в качестве канала управления, периодически отправляя запросы на подконтрольный злоумышленникам DNS сервер. По периодическим запросам на один и тот же домен можно выявить скрытый DNS канал. Есть ли такие IP адреса в исследуемом датасете?**

```{r}
evil_ip <- dns_l %>% 
  group_by(ip = tolower(dns_l$`id.orig_h`), domain = tolower(dns_l$`query `)) %>% 
  summarise(req_count = n()) %>% 
  filter(req_count > 1)

uni_evil <- unique(evil_ip$`ip`)

uni_evil %>% length() 
uni_evil %>% head(10)
```

***Часть 3. Обогащение данных***

**10. Определите местоположение (страну, город) и организацию-провайдера для топ-10 доменов. Для этого можно использовать сторонние сервисы. С нашем случае используем `https://ip-api.com/`.**

```{r}
top_address <- domains_top_10 %>% 
  .[-10,] %>% 
  head(10)

top_address
```

Выведем данные из json файла и выведем его в датафрейме.
```{r}
geo_ip <- fromJSON("top_10.json")
geo_ip_df <- as.data.frame(geo_ip)
geo_ip_df
```

## Оценка результатов

В результате практической работы были получены ответы на все поставленные вопросы с помощью языка R и библиотеки `dplyr`. Дополнительно были изучены возможности редактирования датафрейма, а также посмотрения датафрейма из json файла.

## Вывод

В ходе выполнения практической работы были подготовлены, проанализированы и обогащены данные DNS трафика с помощью стороннего ресурса `https://ip-api.com/` и оформлеты в виде датафрейма.